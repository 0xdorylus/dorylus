# 第一个原则是“清晰明确的提示”

## 大型语言模型的类型

### 基础 LLM


基础 LLM 经过训练，能根据文本训练数据预测下一个词。

通常在互联网和其他来源上接受大量数据的训练，以找出最可能的下一个词。

例如，如果您用“从前，有一只独角兽”作为提示词，它可能会完成这句话，即预测接下来的几个词是“它和所有独角兽朋友一起生活在一个神奇的森林里”。

然而，如果您用“法国的首都是什么”作为提示词，那么基于互联网上的文章，基础LLM可能会完成这句话，例如：“法国最大的城市是什么？法国的人口是多少？”等等。

因为互联网上的文章很可能包含关于法国的一系列问题。


### 指令调优 LLM

与之相反，指令调优LLM是大型语言模型研究和实践发展的重点。

指令调优 LLM 经过训练，能够遵循指令。因此，如果您询问它“法国的首都是什么”，它更有可能输出类似于“法国的首都是巴黎”的答案。

通常情况下，指令调优 LLM 的训练方法是：首先使用基础 LLM，该 LLM 已经在大量文本数据上接受训练；

然后使用输入和输出对其进行微调，使其能够更好地遵循指令。

接下来，通常使用一种名为“从人类反馈中学习强化”的技术（RLHF）进一步优化系统，使其能更好地提供帮助并遵循指令。

指令调优LLM经过训练，可以更有助于用户，更诚实，更无害。

例如，与基础LLM相比，它们不太可能输出有问题的文本，如有害的输出。

在实际应用场景中，许多最佳实践已经向指令调优 LLM 转变。

您在互联网上找到的一些最佳实践可能更适合基础 LLM，但对于目前的大多数实际应用，我们建议大多数人关注指令调 优LLM，因为它们更容易使用，同时由于 OpenAI 和其他 LLM 公司的努力，它们变得更安全、更符合要求。



### 第一个原则是“清晰明确的提示”

当您使用指令调优 LLM 时，请将其视为向另一个人提供指示，例如一个聪明的人，但他们不了解您的任务的具体情况。

因此，当LLM不能正常工作时，有时是因为指示不够清晰。

例如，如果您说：“请给我写一些关于艾伦·图灵的内容。”除此之外，您还需要明确说明您希望文本关注他的科学工作、个人生活还是历史角色等。

如果您能指定希望文本采用的语气，比如专业记者的写作风格，或者更像是随意地给朋友写的便签，那么更有希望OMS生成您想要的内容。

当然，如果您想象一下，让一个刚毕业的大学生为您完成这个任务，如果您甚至可以指定他们事先应该阅读的一些文本片段，以便编写关于艾伦·图灵的文章，那么这甚至可以更好地为他们成功完成这个任务做好准备。

在接下来的课程，您将看到如何清晰明确的例子，这是提示 OMS 的一个重要原则
